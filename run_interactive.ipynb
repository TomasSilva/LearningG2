{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d148214-9dfa-44e5-bcb3-955ff119dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run hyperparameters:\t...edit in hyperparameters/hps.yaml\n",
      "{'metric': False, 'num_samples': 200000, 'saved_model': False, 'saved_model_path': '...', 'n_hidden': 128, 'n_layers': 4, 'activations': 'gelu', 'use_bias': True, 'parameter_initialisation_scale': 1.0, 'embedding_dim': 8, 'epochs': 200, 'batch_size': 32, 'init_learning_rate': 0.001, 'min_learning_rate': 0.0001, 'validate': True, 'val_print': False, 'num_val_samples': 500, 'val_batch_size': 100, 'verbosity': 1, 'print_losses': False, 'print_interval': 1}\n"
     ]
    }
   ],
   "source": [
    "'''Interactive run file for the G2-structure learning'''\n",
    "#...ensure this notebook is using the correct kernel for your virtual environment\n",
    "# Import libraries\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import functions\n",
    "from models.model import (\n",
    "    GlobalModel, TrainingModel, NormalisationLayer, \n",
    "    DenormalisationLayer, NormalisedModel, ScaledGlorotUniform\n",
    ")\n",
    "from sampling.sampling import LinkSample\n",
    "from geometry.compression import form_to_vec, vec_to_form, vec_to_metric\n",
    "from geometry.geometry import exterior_derivative, holomorphic_volume_form_to_real\n",
    "from geometry.wedge_product import wedge_product\n",
    "from geometry.patches import patch_indices_to_scalar\n",
    "\n",
    "# Print the hyperparameters\n",
    "with open(os.getcwd()+'/hyperparameters/hps.yaml', \"r\") as file:\n",
    "    hp = yaml.safe_load(file)\n",
    "print(f'Run hyperparameters:\\t...edit in hyperparameters/hps.yaml\\n{hp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e724e-9b7e-4c7e-9edf-ce90c0c62c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training script\n",
    "model_name = 'test'\n",
    "!python3 -m run {model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31d4077-ddfc-49f8-9411-59390b211d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ed/miniforge3/envs/cymetric/lib/python3.9/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer ScaledGlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import the trained model\n",
    "loaded_model_name = '3form' #model_name #...or set to desired name if not model trained above\n",
    "loaded_model_path = os.getcwd() + f\"/runs/global_model_{loaded_model_name}.keras\" #...reimport the model\n",
    "#loaded_model_path = os.getcwd() + f\"/models/link_models/global_model_3form.keras\" #...import a pre-trained model instead\n",
    "\n",
    "# Custom objects for loading the new architecture\n",
    "custom_objects = {\n",
    "    'GlobalModel': GlobalModel,\n",
    "    'NormalisationLayer': NormalisationLayer,\n",
    "    'DenormalisationLayer': DenormalisationLayer,\n",
    "    'NormalisedModel': NormalisedModel,\n",
    "    'ScaledGlorotUniform': ScaledGlorotUniform\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model(loaded_model_path, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9c48cb-66e6-4596-b583-c09c9d6490aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ed/miniforge3/envs/cymetric/lib/python3.9/site-packages/numpy/linalg/linalg.py:2180: RuntimeWarning: divide by zero encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n",
      "/Users/ed/miniforge3/envs/cymetric/lib/python3.9/site-packages/numpy/linalg/linalg.py:2180: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n",
      "pointgen:INFO:Vol_k: 5.0, Vol_cy: 287.4509097329875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G2 3-forms computed... (shape: (1000, 7, 7, 7))\n"
     ]
    }
   ],
   "source": [
    "# Test loaded model on fake link points\n",
    "# Testing hyperparameters\n",
    "testsize = 1000 #...how many link points to use in the testing\n",
    "\n",
    "# Generate the testing data on the Link\n",
    "test_dataset = LinkSample(testsize)\n",
    "test_linkpts = test_dataset.link_points()\n",
    "test_patch_idxs = patch_indices_to_scalar(test_dataset.one_idxs, test_dataset.dropped_idxs)\n",
    "if not hp[\"metric\"]:\n",
    "    test_link_outputs = test_dataset.g2_form\n",
    "else:\n",
    "    test_link_outputs = test_dataset.g2_metric\n",
    "test_linkpts_tf = tf.convert_to_tensor(test_linkpts)\n",
    "test_link_outputs_tf = tf.convert_to_tensor(test_link_outputs)\n",
    "    \n",
    "# Compute the NN test outputs using the new GlobalModel interface\n",
    "if not hp[\"metric\"]:\n",
    "    # Compute the predicted G2 3-forms (loaded_model returns at original scale)\n",
    "    predicted_g2form_vecs = np.array(loaded_model([test_linkpts_tf, test_patch_idxs]))\n",
    "    predicted_g2forms = np.array(vec_to_form(predicted_g2form_vecs, 7, 3).numpy())\n",
    "    print(f'G2 3-forms computed... (shape: {predicted_g2forms.shape})')\n",
    "else:\n",
    "    # Compute the predicted G2 metrics (loaded_model returns at original scale)\n",
    "    predicted_g2metric_vecs = np.array(loaded_model([test_linkpts_tf, test_patch_idxs]))\n",
    "    predicted_g2metrics = np.array(vec_to_metric(predicted_g2metric_vecs, 7, 3).numpy())\n",
    "    print(f'G2 metrics computed... (shape: {predicted_g2metrics.shape})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01fe010a-57a5-42dc-ba15-8ee88988030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35) (1000, 35)\n",
      "(MAE, MSE, MAPE): (0.035586704, 0.0067762937, 61.774372)\n",
      "Active components: 13948/35000\n",
      "Active MAE: 0.089287\n",
      "Active MAPE: 120.53%\n"
     ]
    }
   ],
   "source": [
    "# More loss testing\n",
    "test_outputs_vecs = form_to_vec(test_link_outputs_tf)\n",
    "print(test_outputs_vecs.shape, predicted_g2form_vecs.shape)\n",
    "\n",
    "# Mask out near-zero components for evaluation\n",
    "def robust_metrics(y_true, y_pred, threshold=0.0001):\n",
    "    mask = np.abs(y_true) > threshold\n",
    "    if np.sum(mask) > 0:\n",
    "        active_true = y_true[mask]\n",
    "        active_pred = y_pred[mask]\n",
    "        \n",
    "        mae_active = np.mean(np.abs(active_true - active_pred))\n",
    "        mape_active = 100 * np.mean(np.abs(active_true - active_pred) / np.abs(active_true))\n",
    "        \n",
    "        return mae_active, mape_active, np.sum(mask)\n",
    "    return None, None, 0\n",
    "\n",
    "# Define losses\n",
    "mae = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "mape = tf.keras.losses.MeanAbsolutePercentageError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "\n",
    "# Compute losses\n",
    "mae_loss = mae(test_outputs_vecs, predicted_g2form_vecs).numpy()\n",
    "mse_loss = mse(test_outputs_vecs, predicted_g2form_vecs).numpy()\n",
    "mape_loss = mape(test_outputs_vecs, predicted_g2form_vecs).numpy()\n",
    "mae_active, mape_active, n_active = robust_metrics(\n",
    "    test_outputs_vecs.numpy().flatten(), \n",
    "    predicted_g2form_vecs.flatten()\n",
    ")\n",
    "\n",
    "# Print losses\n",
    "print(\"(MAE, MSE, MAPE):\", (mae_loss, mse_loss, mape_loss))\n",
    "print(f\"Active components: {n_active}/{np.prod(test_outputs_vecs.shape)}\")\n",
    "print(f\"Active MAE: {mae_active:.6f}\")\n",
    "print(f\"Active MAPE: {mape_active:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204c6a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value statistics:\n",
      "Min: -0.391490\n",
      "Max: 0.391490\n",
      "Mean: -0.000322\n",
      "Values near zero: 25760/35000\n",
      "Per-component MAPE: [1.00930178e+02 4.70856360e-02 6.03072068e-02 1.07362978e+02\n",
      " 9.99496655e-03 3.80023541e-03 1.03402275e+02 1.33976066e-02\n",
      " 7.41064181e-03 2.50791221e-02 8.82899749e-03 5.91055053e+00\n",
      " 1.01883319e+02 2.61216070e+02 1.42612149e+02 1.02486118e+02\n",
      " 1.66094861e-02 8.52139872e-03 1.40476792e-03 3.43749692e-03\n",
      " 1.01205330e+02 2.58808001e+02 2.65315565e-03 6.09898411e+00\n",
      " 2.66387135e+02 1.01535960e+02 9.96059156e-04 1.42606626e+02\n",
      " 3.14401219e-02 2.66699444e+02 6.10201390e+00 1.02350449e+02\n",
      " 1.09349529e-02 2.25876109e-02 5.65234471e-02]\n"
     ]
    }
   ],
   "source": [
    "# Add this analysis in your notebook:\n",
    "print(\"Target value statistics:\")\n",
    "print(f\"Min: {np.min(test_outputs_vecs):.6f}\")\n",
    "print(f\"Max: {np.max(test_outputs_vecs):.6f}\")\n",
    "print(f\"Mean: {np.mean(test_outputs_vecs):.6f}\")\n",
    "print(f\"Values near zero: {np.sum(np.abs(test_outputs_vecs) < 0.01)}/{np.prod(test_outputs_vecs.shape)}\")\n",
    "\n",
    "# Check component-wise errors\n",
    "component_mapes = 100 * np.mean(np.abs(test_outputs_vecs - predicted_g2form_vecs) / \n",
    "                               (np.abs(test_outputs_vecs) + 1e-8), axis=0)\n",
    "print(f\"Per-component MAPE: {component_mapes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b102e1b5-4cfe-4486-b8e4-7d269144b905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G2 3-form exterior derivatives computed... (shape: (1000, 7, 7, 7, 7))\n",
      "\\omega ^ \\omega computed... (shape: (1000, 7, 7, 7, 7))\n",
      "Checking identity d\\phi = \\omega ^ \\omega:\tFalse\n"
     ]
    }
   ],
   "source": [
    "# Compute exterior derivative of 3-forms over the test data\n",
    "# Retrieve the Kahler form for the test dataset\n",
    "test_kahler_form = test_dataset.kahler_form\n",
    "\n",
    "# Compute d\\phi\n",
    "dg2_3form = np.array(exterior_derivative(loaded_model, test_linkpts_tf, test_patch_idxs))\n",
    "print(f'G2 3-form exterior derivatives computed... (shape: {dg2_3form.shape})')\n",
    "###print(f'Non-zero elements: {np.sum(np.where(np.absolute(np.mean(dg2_3form[0],axis=0)) < 1e-5, 1, 0))} / {np.prod(dg2_3form.shape[2:])}')\n",
    "\n",
    "# Compute omega ^ omega\n",
    "omega_wedge_omega = np.array([wedge_product(test_kahler_form[idx], test_kahler_form[idx]) for idx in range(test_kahler_form.shape[0])])\n",
    "print(f'\\omega ^ \\omega computed... (shape: {omega_wedge_omega.shape})')\n",
    "\n",
    "# Check whether dg2_3form == omega_wedge_omega\n",
    "tolerance = 1e3-6\n",
    "print(f'Checking identity d\\phi = \\omega ^ \\omega:\\t{np.allclose(dg2_3form, omega_wedge_omega)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57511a7c-2d62-4cb1-9bae-022b9c8abe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G2 3-form exterior derivatives computed... (shape: (1000, 7, 7, 7, 7))\n",
      "\\omega ^ \\omega computed... (shape: (1000, 7, 7, 7, 7))\n",
      "Checking identity d\\phi = \\omega ^ \\omega:\tFalse\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_hvf_i_R7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e3\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChecking identity d\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mphi = \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124momega ^ \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124momega:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mallclose(dg2_3form,\u001b[38;5;250m \u001b[39momega_wedge_omega)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m im_hvf_wedge_dtheta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([wedge_product(test_hvf_i_R7[i], test_dataset\u001b[38;5;241m.\u001b[39mdthetas[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mtest_hvf_i_R7\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Full \\psi\u001b[39;00m\n\u001b[1;32m     19\u001b[0m psi_v2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m omega_wedge_omega \u001b[38;5;241m+\u001b[39m im_hvf_wedge_dtheta\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_hvf_i_R7' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute exterior derivative of 3-forms over the test data\n",
    "# Retrieve the Kahler form for the test dataset\n",
    "test_kahler_form = test_dataset.kahler_form\n",
    "\n",
    "# Compute d\\phi - use the GlobalModel directly (no .model attribute needed)\n",
    "dg2_3form = np.array(exterior_derivative(loaded_model, test_linkpts_tf, test_patch_idxs))\n",
    "print(f'G2 3-form exterior derivatives computed... (shape: {dg2_3form.shape})')\n",
    "###print(f'Non-zero elements: {np.sum(np.where(np.absolute(np.mean(dg2_3form[0],axis=0)) < 1e-5, 1, 0))} / {np.prod(dg2_3form.shape[2:])}')\n",
    "\n",
    "# Compute omega ^ omega\n",
    "omega_wedge_omega = np.array([wedge_product(test_kahler_form[idx], test_kahler_form[idx]) for idx in range(test_kahler_form.shape[0])])\n",
    "print(f'\\omega ^ \\omega computed... (shape: {omega_wedge_omega.shape})')\n",
    "\n",
    "# Check whether dg2_3form == omega_wedge_omega\n",
    "tolerance = 1e3-6\n",
    "print(f'Checking identity d\\phi = \\omega ^ \\omega:\\t{np.allclose(dg2_3form, omega_wedge_omega)}')\n",
    "im_hvf_wedge_dtheta = np.array([wedge_product(test_hvf_i_R7[i], test_dataset.dthetas[i]) for i in range(test_hvf_i_R7.shape[0])])\n",
    "# Full \\psi\n",
    "psi_v2 = 0.5 * omega_wedge_omega + im_hvf_wedge_dtheta\n",
    "\n",
    "print(psi_v2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731da13-8db4-4dca-aa27-e14b59aacb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### IGNORE BELOW ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcce8a-86d3-4be0-8041-abf84efd8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###manual checking -- deleteee\n",
    "#np.sum(np.where(np.absolute(omega_wedge_omega) > 1e-8, 1, 0)),np.sum(np.where(np.absolute(dg2_3form) > 1e-8, 1, 0))\n",
    "#print(np.min(dg2_3form), np.mean(dg2_3form), np.max(dg2_3form))\n",
    "#print(np.min(omega_wedge_omega), np.mean(omega_wedge_omega), np.max(omega_wedge_omega))\n",
    "\n",
    "'''\n",
    "for pt_idx in range(identity_test_size):\n",
    "    print(np.mean(np.absolute(dg2_3form[0][pt_idx] - omega_wedge_omega[pt_idx])))\n",
    "    ###reduce to non-zero?\n",
    "    #--> consistently baddd\n",
    "'''\n",
    "\n",
    "print(np.mean(test_linkpts, axis=0), np.std(test_linkpts, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b20c86-ec69-4d7b-998c-71ddcf7b3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "###testinggg\n",
    "from geometry.geometry import wedge_product, wedge_form2_with_form1\n",
    "fake_batchsize = 10\n",
    "'''#tf\n",
    "fake_2_forms = tf.random.normal((fake_batchsize, 6, 6))\n",
    "fake_2_forms = fake_2_forms - tf.transpose(fake_2_forms, perm=[0, 2, 1])\n",
    "fake_1_forms = tf.random.normal((fake_batchsize, 7))\n",
    "'''\n",
    "#np\n",
    "fake_2_forms = np.random.randn(fake_batchsize, 6, 6)\n",
    "fake_2_forms_66 = fake_2_forms - np.transpose(fake_2_forms, axes=[0, 2, 1])\n",
    "fake_2_forms_77 = np.pad(fake_2_forms_66, ((0,0), (0,1), (0,1)), mode='constant')\n",
    "fake_1_forms = np.random.normal(size=(fake_batchsize, 7))\n",
    "print(f'Data shapes: {fake_2_forms.shape}, {fake_1_forms.shape}')\n",
    "\n",
    "# old functionality:\n",
    "output_old = wedge_form2_with_form1(fake_2_forms_66, fake_1_forms)\n",
    "output_new = np.array([wedge_product(fake_2_forms_77[idx], fake_1_forms[idx]) for idx in range(fake_1_forms.shape[0])])\n",
    "\n",
    "# scale output_old to match output_new\n",
    "output_old *= 3 ###why is there this factor of 3 difference?\n",
    "\n",
    "print(f'Output shapes: {output_old.shape}, {output_new.shape}')\n",
    "print(f'Matching?? --> {np.allclose(output_old, output_new)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcaeacb-4ec3-4850-be5d-bac62305cd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cymetric",
   "language": "python",
   "name": "cymetric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
