{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d148214-9dfa-44e5-bcb3-955ff119dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run hyperparameters:\t...edit in hyperparameters/hps.yaml\n",
      "{'metric': False, 'n_patches': 1, 'overlap_upperwidth': 0.1, 'num_samples': 200000, 'saved_model': False, 'saved_model_path': '...', 'n_hidden': 64, 'n_layers': 3, 'activations': 'gelu', 'use_bias': True, 'epochs': 200, 'batch_size': 100, 'init_learning_rate': 0.005, 'min_learning_rate': 0.005, 'validate': False, 'val_print': False, 'num_val_samples': 500, 'val_batch_size': 100, 'verbosity': 1, 'print_losses': False, 'print_interval': 1}\n"
     ]
    }
   ],
   "source": [
    "'''Interactive run file for the G2-structure learning'''\n",
    "#...ensure this notebook is using the correct kernel for your virtual environment\n",
    "# Import libraries\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import functions\n",
    "from models.model import GlobalModel, PatchSubModel\n",
    "from sampling.sampling import LinkSample\n",
    "from geometry.compression import vec_to_form, vec_to_metric\n",
    "from geometry.patches import PatchChange_Coords, PatchChange_G2form, PatchChange_G2metric\n",
    "from geometry.geometry import exterior_derivative\n",
    "\n",
    "# Print the hyperparameters\n",
    "with open(os.getcwd()+'/hyperparameters/hps.yaml', \"r\") as file:\n",
    "    hp = yaml.safe_load(file)\n",
    "print(f'Run hyperparameters:\\t...edit in hyperparameters/hps.yaml\\n{hp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e724e-9b7e-4c7e-9edf-ce90c0c62c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the script\n",
    "model_name = 'test'\n",
    "!python3 -m run {model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31d4077-ddfc-49f8-9411-59390b211d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "absl:WARNING:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Import the trained model\n",
    "#loaded_model_name = model_name #...or set to desired name if not model trained above\n",
    "#loaded_model_path = os.getcwd() + f\"/runs/link_model_{loaded_model_name}.keras\" #...reimport the model\n",
    "loaded_model_path = os.getcwd() + f\"/models/link_models/link_model_3form.keras\" #...import a pre-trained model instead\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model(loaded_model_path, custom_objects={'GlobalModel': GlobalModel, 'PatchSubModel': PatchSubModel})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9c48cb-66e6-4596-b583-c09c9d6490aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "G2 3-forms computed... (shape: (1, 10, 7, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test loaded model on fake link points\n",
    "testsize = 10\n",
    "# Generate the fake data --> ### replace with proper link sampling\n",
    "fake_linkpts = np.array([np.random.normal(size=(testsize, 7)) for patch_idx in range(loaded_model.n_patches)]) ###need to edit to use the patch transform functions\n",
    "\n",
    "if not hp[\"metric\"]:\n",
    "    # Compute the predicted G2 3-forms\n",
    "    predicted_g2form_vecs = np.array([loaded_model.patch_submodels[patch_idx].predict(fake_linkpts[patch_idx]) for patch_idx in range(loaded_model.n_patches)])\n",
    "    predicted_g2forms = np.array([vec_to_form(predicted_g2form_vecs[patch_idx], 7, 3).numpy() for patch_idx in range(loaded_model.n_patches)])\n",
    "    print(f'G2 3-forms computed... (shape: {predicted_g2forms.shape}')\n",
    "\n",
    "else:\n",
    "    # Compute the predicted G2 metrics\n",
    "    predicted_g2metric_vecs = np.array([loaded_model.patch_submodels[patch_idx].predict(fake_linkpts[patch_idx]) for patch_idx in range(loaded_model.n_patches)])\n",
    "    predicted_g2metrics = np.array([vec_to_metric(predicted_g2form_vecs[patch_idx], 7, 3).numpy() for patch_idx in range(loaded_model.n_patches)])\n",
    "    print(f'G2 metrics computed... (shape: {predicted_g2metrics.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b102e1b5-4cfe-4486-b8e4-7d269144b905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G2 3-form exterior derivatives computed... (shape: (1, 10, 7, 7, 7, 7)\n",
      "Non-zero elements: 1027 / 2401\n"
     ]
    }
   ],
   "source": [
    "# Compute exterior derivative of 3-forms over the test data\n",
    "assert hp[\"metric\"] == False, \"Exterior derivative only configured for the G2 3-form.\"\n",
    "\n",
    "# Compute d\\phi\n",
    "dg2_3form = np.array([exterior_derivative(loaded_model.patch_submodels[patch_idx], fake_linkpts[patch_idx]) for patch_idx in range(loaded_model.n_patches)])\n",
    "print(f'G2 3-form exterior derivatives computed... (shape: {dg2_3form.shape}')\n",
    "\n",
    "# Run general check\n",
    "print(f'Non-zero elements: {np.sum(np.where(np.absolute(np.mean(dg2_3form[0],axis=0)) < 1e-5, 1, 0))} / {np.prod(dg2_3form.shape[2:])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731da13-8db4-4dca-aa27-e14b59aacb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b20c86-ec69-4d7b-998c-71ddcf7b3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "###testinggg\n",
    "from geometry.geometry import wedge_product, wedge_form2_with_form1\n",
    "fake_batchsize = 10\n",
    "'''#tf\n",
    "fake_2_forms = tf.random.normal((fake_batchsize, 6, 6))\n",
    "fake_2_forms = fake_2_forms - tf.transpose(fake_2_forms, perm=[0, 2, 1])\n",
    "fake_1_forms = tf.random.normal((fake_batchsize, 7))\n",
    "'''\n",
    "#np\n",
    "fake_2_forms = np.random.randn(fake_batchsize, 6, 6)\n",
    "fake_2_forms_66 = fake_2_forms - np.transpose(fake_2_forms, axes=[0, 2, 1])\n",
    "fake_2_forms_77 = np.pad(fake_2_forms_66, ((0,0), (0,1), (0,1)), mode='constant')\n",
    "fake_1_forms = np.random.normal(size=(fake_batchsize, 7))\n",
    "print(f'Data shapes: {fake_2_forms.shape}, {fake_1_forms.shape}')\n",
    "\n",
    "# old functionality:\n",
    "output_old = wedge_form2_with_form1(fake_2_forms_66, fake_1_forms)\n",
    "output_new = np.array([wedge_product(fake_2_forms_77[idx], fake_1_forms[idx]) for idx in range(fake_1_forms.shape[0])])\n",
    "\n",
    "# scale output_old to match output_new\n",
    "output_old *= 3 ###why is there this factor of 3 difference?\n",
    "\n",
    "print(f'Output shapes: {output_old.shape}, {output_new.shape}')\n",
    "print(f'Matching?? --> {np.allclose(output_old, output_new)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cymetric",
   "language": "python",
   "name": "cymetric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
