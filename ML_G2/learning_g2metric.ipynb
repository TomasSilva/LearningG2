{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "PROJECT_ROOT = pathlib.Path.cwd().parent  # LearningG2\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../sampling/g2_dataset.npz\")\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Split\n",
    "# -----------------------\n",
    "def split_train_val_test(X, Y, train=0.90, val=0.05, seed=42):\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    Y = np.asarray(Y, dtype=np.float32)\n",
    "    assert X.shape[0] == Y.shape[0]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    n_tr = int(train * N)\n",
    "    n_va = int(val * N)\n",
    "    tr = idx[:n_tr]\n",
    "    va = idx[n_tr:n_tr + n_va]\n",
    "    te = idx[n_tr + n_va:]\n",
    "\n",
    "    return (X[tr], Y[tr]), (X[va], Y[va]), (X[te], Y[te])\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Model\n",
    "# -----------------------\n",
    "def build_regressor(input_dim=19, output_dim=28, hidden=(512, 512, 256, 256), dropout=0.0):\n",
    "    inp = keras.Input(shape=(input_dim,), dtype=tf.float32)\n",
    "    x = inp\n",
    "    for w in hidden:\n",
    "        x = layers.Dense(w, activation=\"gelu\")(x)\n",
    "        if dropout and dropout > 0:\n",
    "            x = layers.Dropout(dropout)(x)\n",
    "    out = layers.Dense(output_dim, dtype=tf.float32)(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Train\n",
    "# -----------------------\n",
    "def train_regressor_19_to_28(\n",
    "    X, Y,\n",
    "    seed=42,\n",
    "    batch=2048,\n",
    "    epochs=200,\n",
    "    lr=1e-3,\n",
    "    hidden=(512, 512, 256, 256),\n",
    "    dropout=0.0,\n",
    "    checkpoint_path=\"regressor_19_to_28.keras\",\n",
    "):\n",
    "    (Xtr, Ytr), (Xva, Yva), (Xte, Yte) = split_train_val_test(X, Y, seed=seed)\n",
    "\n",
    "    # Normalization layers (fit on train only)\n",
    "    x_norm = layers.Normalization(axis=-1, name=\"x_norm\")\n",
    "    y_norm = layers.Normalization(axis=-1, name=\"y_norm\")\n",
    "    x_norm.adapt(Xtr)\n",
    "    y_norm.adapt(Ytr)\n",
    "\n",
    "    # Build model that outputs normalized Y\n",
    "    base = build_regressor(\n",
    "        input_dim=Xtr.shape[1],\n",
    "        output_dim=Ytr.shape[1],\n",
    "        hidden=hidden,\n",
    "        dropout=dropout\n",
    "    )\n",
    "\n",
    "    inp = keras.Input(shape=(Xtr.shape[1],), dtype=tf.float32)\n",
    "    x = x_norm(inp)\n",
    "    yhat_norm = base(x)\n",
    "    model = keras.Model(inp, yhat_norm, name=\"regressor_19_to_28_normY\")\n",
    "\n",
    "    # Loss/metrics in normalized Y space\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\n",
    "            keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            keras.metrics.RootMeanSquaredError(name=\"rmse\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # tf.data for speed\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((Xtr, y_norm(Ytr))) \\\n",
    "        .shuffle(min(len(Xtr), 200_000), seed=seed, reshuffle_each_iteration=True) \\\n",
    "        .batch(batch) \\\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((Xva, y_norm(Yva))) \\\n",
    "        .batch(batch) \\\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    cb = [\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=20, restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_path, monitor=\"val_loss\", save_best_only=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=cb,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predict in normalized space, then unnormalize back to original scale\n",
    "    Ypred_norm = model.predict(Xte, batch_size=8192, verbose=0)\n",
    "\n",
    "    y_mean = y_norm.mean.numpy()\n",
    "    y_std  = np.sqrt(y_norm.variance.numpy())\n",
    "    Ypred = y_mean + Ypred_norm * y_std\n",
    "\n",
    "    # Also: get model metrics on normalized test targets (for sanity)\n",
    "    test_metrics_norm = model.evaluate(\n",
    "        Xte, y_norm(Yte), batch_size=8192, verbose=0, return_dict=True\n",
    "    )\n",
    "\n",
    "    return model, hist, (Xte, Yte, Ypred), (x_norm, y_norm), test_metrics_norm\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Metrics + plots\n",
    "# -----------------------\n",
    "def plot_history(hist):\n",
    "    # loss\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(hist.history[\"loss\"], label=\"train loss\")\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"val loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"MSE (normalized)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # mae/rmse if present\n",
    "    for k in [\"mae\", \"rmse\"]:\n",
    "        if k in hist.history:\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.plot(hist.history[k], label=f\"train {k}\")\n",
    "            plt.plot(hist.history.get(f\"val_{k}\", []), label=f\"val {k}\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.ylabel(f\"{k} (normalized)\")\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def plot_true_vs_pred(Y_true, Y_pred, n_points=30000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = Y_true.shape[0]\n",
    "    idx = rng.choice(N, min(N, n_points), replace=False)\n",
    "    yt = Y_true[idx].reshape(-1)\n",
    "    yp = Y_pred[idx].reshape(-1)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(yt, yp, s=2, alpha=0.25)\n",
    "    lo = min(yt.min(), yp.min())\n",
    "    hi = max(yt.max(), yp.max())\n",
    "    plt.plot([lo, hi], [lo, hi], \"r--\", lw=1)\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate(Y_true, Y_pred):\n",
    "    err = Y_pred - Y_true\n",
    "    mae = np.mean(np.abs(err), axis=0)\n",
    "    rmse = np.sqrt(np.mean(err**2, axis=0))\n",
    "\n",
    "    print(\"Per-component MAE (min/median/max):\", float(mae.min()), float(np.median(mae)), float(mae.max()))\n",
    "    print(\"Per-component RMSE (min/median/max):\", float(rmse.min()), float(np.median(rmse)), float(rmse.max()))\n",
    "    print(\"Global MAE:\", float(np.mean(np.abs(err))))\n",
    "    print(\"Global RMSE:\", float(np.sqrt(np.mean(err**2))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37349a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_triangular_part(A, include_diagonal=True):\n",
    "    \"\"\"\n",
    "    Extract the upper triangular part of a 7x7 matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array_like, shape (7,7)\n",
    "        Input matrix.\n",
    "    include_diagonal : bool\n",
    "        Whether to include the diagonal entries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    v : ndarray, shape (28,) if include_diagonal else (21,)\n",
    "        Upper triangular entries in row-major order.\n",
    "    \"\"\"\n",
    "    A = np.asarray(A)\n",
    "    assert A.shape == (7, 7), \"Input must be a 7x7 matrix\"\n",
    "\n",
    "    if include_diagonal:\n",
    "        idx = np.triu_indices(7)\n",
    "    else:\n",
    "        idx = np.triu_indices(7, k=1)\n",
    "\n",
    "    return A[idx]\n",
    "\n",
    "X = np.concatenate([data['link_points'], data['etas'], data['drop_maxs'][:,None], data['drop_ones'][:,None]], axis=1)\n",
    "G = data[\"g2_metrics\"]        # shape (N, 7, 7)\n",
    "idx = np.triu_indices(7)     # include_diagonal=True by default\n",
    "Y = G[:, idx[0], idx[1]]   \n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Example usage\n",
    "# -----------------------\n",
    "# X: (N,19), Y: (N,28)\n",
    "model, hist, (Xte, Yte, Ypred), (x_norm, y_norm), test_metrics_norm = train_regressor_19_to_28(\n",
    "    X, Y,\n",
    "    batch=2048,\n",
    "    epochs=200,\n",
    "    lr=1e-3,\n",
    "    hidden=(512, 512, 256, 256),\n",
    "    dropout=0.0\n",
    ")\n",
    "plot_history(hist)\n",
    "plot_true_vs_pred(Yte, Ypred)\n",
    "evaluate(Yte, Ypred)\n",
    "print(\"Test metrics in normalized space:\", test_metrics_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "G2 ML Environment",
   "language": "python",
   "name": "g2_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
