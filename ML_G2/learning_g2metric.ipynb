{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a3dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/tomassilva/Desktop/GitHub/LearningG2\n"
     ]
    }
   ],
   "source": [
    "import sys, pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "PROJECT_ROOT = pathlib.Path.cwd().parent  # LearningG2\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e78f6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_points',\n",
       " 'link_points',\n",
       " 'rotations',\n",
       " 'phis',\n",
       " 'psis',\n",
       " 'riemannian_metrics',\n",
       " 'g2_metrics',\n",
       " 'drop_maxs',\n",
       " 'drop_ones',\n",
       " 'etas']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"../sampling/g2_dataset.npz\")\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fea40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Data utils\n",
    "# -------------------------\n",
    "def split_data(X, Y, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = X.shape[0]\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    n_tr = int(0.9 * N)\n",
    "    n_va = int(0.05 * N)\n",
    "\n",
    "    tr = idx[:n_tr]\n",
    "    va = idx[n_tr:n_tr + n_va]\n",
    "    te = idx[n_tr + n_va:]\n",
    "    return (X[tr], Y[tr]), (X[va], Y[va]), (X[te], Y[te])\n",
    "\n",
    "\n",
    "def normalize_data(Xtr, Ytr):\n",
    "    x_scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "    Xtr_n = x_scaler.fit_transform(Xtr)\n",
    "    Ytr_n = y_scaler.fit_transform(Ytr)\n",
    "    return Xtr_n, Ytr_n, x_scaler, y_scaler\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Model\n",
    "# -------------------------\n",
    "def build_regressor_19_to_28():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(19,)),\n",
    "        layers.Dense(512, activation=\"gelu\"),\n",
    "        layers.Dense(512, activation=\"gelu\"),\n",
    "        layers.Dense(256, activation=\"gelu\"),\n",
    "        layers.Dense(256, activation=\"gelu\"),\n",
    "        layers.Dense(28)  # linear output\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Plots\n",
    "# -------------------------\n",
    "def plot_training_history(history):\n",
    "    h = history.history\n",
    "    epochs = np.arange(1, len(h[\"loss\"]) + 1)\n",
    "\n",
    "    # Loss\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(epochs, h[\"loss\"], label=\"train loss\")\n",
    "    if \"val_loss\" in h:\n",
    "        plt.plot(epochs, h[\"val_loss\"], label=\"val loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # MAE\n",
    "    if \"mae\" in h:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        plt.plot(epochs, h[\"mae\"], label=\"train MAE\")\n",
    "        if \"val_mae\" in h:\n",
    "            plt.plot(epochs, h[\"val_mae\"], label=\"val MAE\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"MAE\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_true_vs_pred(Y_true, Y_pred, n_points=20000, title=\"True vs Pred\"):\n",
    "    yt = Y_true.reshape(-1)\n",
    "    yp = Y_pred.reshape(-1)\n",
    "\n",
    "    n = min(len(yt), n_points)\n",
    "    idx = np.random.choice(len(yt), size=n, replace=False)\n",
    "    yt = yt[idx]\n",
    "    yp = yp[idx]\n",
    "\n",
    "    lo = min(yt.min(), yp.min())\n",
    "    hi = max(yt.max(), yp.max())\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(yt, yp, s=2, alpha=0.25)\n",
    "    plt.plot([lo, hi], [lo, hi], \"r--\")\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Train + evaluate\n",
    "# -------------------------\n",
    "def train_regressor_19_to_28(\n",
    "    X, Y,\n",
    "    batch=2048,\n",
    "    epochs=150,\n",
    "    lr=1e-3,\n",
    "    seed=42,\n",
    "    do_plots=True\n",
    "):\n",
    "    \"\"\"\n",
    "    X: (N,19)\n",
    "    Y: (N,28)\n",
    "    Returns:\n",
    "      model, (Xte_n, Yte_true, Yte_pred), (x_scaler, y_scaler), history\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    assert X.ndim == 2 and X.shape[1] == 19, f\"X must be (N,19), got {X.shape}\"\n",
    "    assert Y.ndim == 2 and Y.shape[1] == 28, f\"Y must be (N,28), got {Y.shape}\"\n",
    "\n",
    "    (Xtr, Ytr), (Xva, Yva), (Xte, Yte) = split_data(X, Y, seed=seed)\n",
    "\n",
    "    # normalize\n",
    "    Xtr_n, Ytr_n, x_scaler, y_scaler = normalize_data(Xtr, Ytr)\n",
    "    Xva_n = x_scaler.transform(Xva)\n",
    "    Yva_n = y_scaler.transform(Yva)\n",
    "    Xte_n = x_scaler.transform(Xte)\n",
    "    Yte_n = y_scaler.transform(Yte)\n",
    "\n",
    "    # model\n",
    "    model = build_regressor_19_to_28()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=20, restore_best_weights=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        Xtr_n, Ytr_n,\n",
    "        validation_data=(Xva_n, Yva_n),\n",
    "        batch_size=batch,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # predictions in original scale\n",
    "    Ypred_n = model.predict(Xte_n, batch_size=8192, verbose=0)\n",
    "    Ypred = y_scaler.inverse_transform(Ypred_n)\n",
    "    Ytrue = y_scaler.inverse_transform(Yte_n)\n",
    "\n",
    "    if do_plots:\n",
    "        plot_training_history(history)\n",
    "        plot_true_vs_pred(Ytrue, Ypred, n_points=20000, title=\"Test set: 28 outputs (flattened)\")\n",
    "\n",
    "    return model, (Xte_n, Ytrue, Ypred), (x_scaler, y_scaler), history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d37349a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 19), (200000, 28))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upper_triangular_part(A, include_diagonal=True):\n",
    "    \"\"\"\n",
    "    Extract the upper triangular part of a 7x7 matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array_like, shape (7,7)\n",
    "        Input matrix.\n",
    "    include_diagonal : bool\n",
    "        Whether to include the diagonal entries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    v : ndarray, shape (28,) if include_diagonal else (21,)\n",
    "        Upper triangular entries in row-major order.\n",
    "    \"\"\"\n",
    "    A = np.asarray(A)\n",
    "    assert A.shape == (7, 7), \"Input must be a 7x7 matrix\"\n",
    "\n",
    "    if include_diagonal:\n",
    "        idx = np.triu_indices(7)\n",
    "    else:\n",
    "        idx = np.triu_indices(7, k=1)\n",
    "\n",
    "    return A[idx]\n",
    "\n",
    "X = np.concatenate([data['link_points'], data['etas'], data['drop_maxs'][:,None], data['drop_ones'][:,None]], axis=1)\n",
    "G = data[\"g2_metrics\"]        # shape (N, 7, 7)\n",
    "idx = np.triu_indices(7)     # include_diagonal=True by default\n",
    "Y = G[:, idx[0], idx[1]]   \n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.7370 - mae: 0.5044 - val_loss: 0.5444 - val_mae: 0.3605 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.5372 - mae: 0.3602 - val_loss: 0.5050 - val_mae: 0.3487 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.5017 - mae: 0.3492 - val_loss: 0.4747 - val_mae: 0.3422 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.4610 - mae: 0.3384 - val_loss: 0.4338 - val_mae: 0.3252 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.4219 - mae: 0.3213 - val_loss: 0.3952 - val_mae: 0.3106 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.3820 - mae: 0.3073 - val_loss: 0.3642 - val_mae: 0.3014 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.3471 - mae: 0.2943 - val_loss: 0.3337 - val_mae: 0.2886 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.3211 - mae: 0.2863 - val_loss: 0.3050 - val_mae: 0.2788 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.2886 - mae: 0.2745 - val_loss: 0.2739 - val_mae: 0.2648 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.2561 - mae: 0.2614 - val_loss: 0.2465 - val_mae: 0.2529 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.2259 - mae: 0.2476 - val_loss: 0.2223 - val_mae: 0.2438 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.2001 - mae: 0.2366 - val_loss: 0.1962 - val_mae: 0.2325 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.1699 - mae: 0.2231 - val_loss: 0.1694 - val_mae: 0.2218 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.1424 - mae: 0.2106 - val_loss: 0.1374 - val_mae: 0.2051 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.1149 - mae: 0.1949 - val_loss: 0.1135 - val_mae: 0.1903 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0946 - mae: 0.1798 - val_loss: 0.0954 - val_mae: 0.1760 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0788 - mae: 0.1659 - val_loss: 0.0809 - val_mae: 0.1626 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0677 - mae: 0.1544 - val_loss: 0.0711 - val_mae: 0.1525 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0598 - mae: 0.1450 - val_loss: 0.0636 - val_mae: 0.1447 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0533 - mae: 0.1368 - val_loss: 0.0588 - val_mae: 0.1394 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0492 - mae: 0.1310 - val_loss: 0.0542 - val_mae: 0.1326 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0450 - mae: 0.1247 - val_loss: 0.0499 - val_mae: 0.1267 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0426 - mae: 0.1205 - val_loss: 0.0470 - val_mae: 0.1225 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0394 - mae: 0.1154 - val_loss: 0.0447 - val_mae: 0.1191 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0373 - mae: 0.1120 - val_loss: 0.0422 - val_mae: 0.1150 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0359 - mae: 0.1091 - val_loss: 0.0411 - val_mae: 0.1132 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m81/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0342 - mae: 0.1061"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Example usage (you provide X, Y)\n",
    "# -------------------------\n",
    "# X = ...  # (N,19)\n",
    "# Y = ...  # (N,28)\n",
    "model, (Xte_n, Ytrue, Ypred), scalers, history = train_regressor_19_to_28(X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g2_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
