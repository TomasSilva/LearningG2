{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "PROJECT_ROOT = pathlib.Path.cwd().parent  # LearningG2\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../sampling/g2_dataset.npz\")\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Split\n",
    "# -----------------------\n",
    "def split_train_val_test(X, Y, train=0.90, val=0.05, seed=42):\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    Y = np.asarray(Y, dtype=np.float32)\n",
    "    assert X.shape[0] == Y.shape[0]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    n_tr = int(train * N)\n",
    "    n_va = int(val * N)\n",
    "    tr = idx[:n_tr]\n",
    "    va = idx[n_tr:n_tr+n_va]\n",
    "    te = idx[n_tr+n_va:]\n",
    "\n",
    "    return (X[tr], Y[tr]), (X[va], Y[va]), (X[te], Y[te])\n",
    "\n",
    "# -----------------------\n",
    "# Model\n",
    "# -----------------------\n",
    "def build_regressor(input_dim=19, output_dim=35, hidden=(512, 512, 256, 256), dropout=0.0):\n",
    "    inp = keras.Input(shape=(input_dim,), dtype=tf.float32)\n",
    "\n",
    "    x = inp\n",
    "    for w in hidden:\n",
    "        x = layers.Dense(w, activation=\"gelu\")(x)\n",
    "        if dropout and dropout > 0:\n",
    "            x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    out = layers.Dense(output_dim, dtype=tf.float32)(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "# -----------------------\n",
    "# Train\n",
    "# -----------------------\n",
    "def train_regressor_19_to_35(\n",
    "    X, Y,\n",
    "    seed=42,\n",
    "    batch=2048,\n",
    "    epochs=200,\n",
    "    lr=1e-3,\n",
    "    hidden=(512, 512, 256, 256),\n",
    "    dropout=0.0\n",
    "):\n",
    "    (Xtr, Ytr), (Xva, Yva), (Xte, Yte) = split_train_val_test(X, Y, seed=seed)\n",
    "\n",
    "    # Normalization layers (fit on train only)\n",
    "    x_norm = layers.Normalization(axis=-1)\n",
    "    y_norm = layers.Normalization(axis=-1)\n",
    "\n",
    "    x_norm.adapt(Xtr)\n",
    "    y_norm.adapt(Ytr)\n",
    "\n",
    "    # Build model that outputs normalized Y\n",
    "    base = build_regressor(input_dim=Xtr.shape[1], output_dim=Ytr.shape[1], hidden=hidden, dropout=dropout)\n",
    "\n",
    "    inp = keras.Input(shape=(Xtr.shape[1],), dtype=tf.float32)\n",
    "    x = x_norm(inp)\n",
    "    yhat_norm = base(x)\n",
    "    model = keras.Model(inp, yhat_norm)\n",
    "\n",
    "    # Loss in normalized Y space\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr),\n",
    "        loss=\"mse\",\n",
    "        metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "    )\n",
    "\n",
    "    # tf.data for speed\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((Xtr, y_norm(Ytr))).shuffle(\n",
    "        min(len(Xtr), 200_000), seed=seed, reshuffle_each_iteration=True\n",
    "    ).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((Xva, y_norm(Yva))).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    cb = [\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6),\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True),\n",
    "        keras.callbacks.ModelCheckpoint(\"regressor_19_to_35.keras\", monitor=\"val_loss\", save_best_only=True),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=cb, verbose=1)\n",
    "\n",
    "    # Predict in normalized space, then unnormalize\n",
    "    Ypred_norm = model.predict(Xte, batch_size=8192, verbose=0)\n",
    "    Ypred = y_norm.mean.numpy() + Ypred_norm * np.sqrt(y_norm.variance.numpy())\n",
    "\n",
    "    return model, hist, (Xte, Yte, Ypred), (x_norm, y_norm)\n",
    "\n",
    "# -----------------------\n",
    "# Metrics + plots\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "def plot_history(hist):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(hist.history[\"loss\"], label=\"train loss\")\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"val loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"MSE (normalized)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_true_vs_pred(Y_true, Y_pred, n_points=30000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = Y_true.shape[0]\n",
    "    idx = rng.choice(N, min(N, n_points), replace=False)\n",
    "    yt = Y_true[idx].reshape(-1)\n",
    "    yp = Y_pred[idx].reshape(-1)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(yt, yp, s=2, alpha=0.25)\n",
    "    lo = min(yt.min(), yp.min())\n",
    "    hi = max(yt.max(), yp.max())\n",
    "    plt.plot([lo, hi], [lo, hi], \"r--\", lw=1)\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate(Y_true, Y_pred):\n",
    "    err = Y_pred - Y_true\n",
    "    mae = np.mean(np.abs(err), axis=0)\n",
    "    rmse = np.sqrt(np.mean(err**2, axis=0))\n",
    "\n",
    "    print(\"Per-component MAE (min/median/max):\", float(mae.min()), float(np.median(mae)), float(mae.max()))\n",
    "    print(\"Per-component RMSE (min/median/max):\", float(rmse.min()), float(np.median(rmse)), float(rmse.max()))\n",
    "    print(\"Global MAE:\", float(np.mean(np.abs(err))))\n",
    "    print(\"Global RMSE:\", float(np.sqrt(np.mean(err**2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oriented35_components(T):\n",
    "    T = np.asarray(T)\n",
    "    assert T.shape == (7,7,7)\n",
    "    triples = list(itertools.combinations(range(7), 3))\n",
    "    vals = np.array([T[i,j,k] for (i,j,k) in triples], dtype=T.dtype)\n",
    "    return vals\n",
    "\n",
    "X = np.concatenate([data['link_points'], data['etas'], data['drop_maxs'][:,None], data['drop_ones'][:,None]], axis=1)\n",
    "Y = np.array([oriented35_components(phi) for phi in data['phis']])\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, hist, (X_test, Y_test, Y_pred), norms = train_regressor_19_to_35(\n",
    "    X, Y,\n",
    "    batch=2048,\n",
    "    epochs=200,\n",
    "    lr=1e-3,\n",
    "    hidden=(512, 512, 256, 256),\n",
    "    dropout=0.0\n",
    ")\n",
    "\n",
    "plot_history(hist)\n",
    "evaluate(Y_test, Y_pred)\n",
    "plot_true_vs_pred(Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g2_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
