### Hyperparameters for the G2-structure learning runs ###

###############################################################################
# Geometric set-up
# Select whether to learn the G2-metric
metric: false

###############################################################################
# Data set-up
# Number of samples to generate for training
num_samples: 200000

###############################################################################
# Model set-up
# Import a saved model instead of initiating a new one (null means randomly initialise)
saved_model: false
saved_model_path: ...
# ...the below are ignored if `saved_model` is true and a model is imported

# Number of hidden units in each layer
n_hidden: 128

# Number of layers in the neural network
n_layers: 4

# Activation function to use in the neural network (e.g., gelu, relu)
activations: gelu

# Whether to use bias terms in the neural network layers
use_bias: true

# Scale for the model parameter uniform initialisation
parameter_initialisation_scale: 1.0

# Dimension of the patch-index embedding layer
embedding_dim: 8

###############################################################################
# Training set-up
# Number of training epochs
epochs: 200

# Batch size for training
batch_size: 32

# Learning rate for the optimizer
init_learning_rate: 0.001
min_learning_rate: 0.0001

# Validation hyperparameters
validate: true
val_print: false
num_val_samples: 500
val_batch_size: 100

# Verbosity level for print logging (e.g., 0 for silent, 1 for progress messages)
verbosity: 1

###############################################################################
#Logging set-up
###where to save the models too

# Whether to print a breakdown of individual loss terms with each training step
print_losses: false
print_interval: 1   
